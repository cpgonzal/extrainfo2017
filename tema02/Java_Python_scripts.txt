1) Hadoop wordcount (java):


/************/
cd hadoop_wordcount

#asegurarse de compilar con java 7
sudo update-alternatives --config javac

javac -classpath $HADOOP_HOME/share/hadoop/common/lib/hadoop-annotations-2.7.0.jar:\
$HADOOP_HOME/share/hadoop/common/hadoop-common-2.7.0.jar:\
$HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.0.jar:\
$HADOOP_HOME/share/hadoop/common/lib/commons-cli-1.2.jar -d bin src/mapred/WordCount.java


cd bin
jar cf mapred.jar mapred/*.class

hadoop fs -mkdir input2
hadoop fs -copyFromLocal ~/workspace_profesor/data/texto_big_data.txt input2/ 
hadoop fs -ls input2/
hadoop jar mapred.jar mapred.WordCount input2 output2
hadoop fs -cat output2/*
hadoop fs -rm -r output2
/**************/





2) Sequential wordcount (python):

/************/
cd python_wordcount

echo "hay muchas, pero que muchas cosas que aprender en esto del big data" | python mapper.py
echo "hay muchas, pero que muchas cosas que aprender en esto del big data" | python mapper.py | sort -k1,1 | python reducer.py

python wordcount.py books.json | sort
/************/



3) Hadoop wordcount (python):

/************/
cd python_wordcount
hadoop fs -rm -r output2

hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-2.6.0.jar \
-file mapper.py    -mapper mapper.py \
-file reducer.py   -reducer reducer.py \
-input input2/* -output output2

hadoop fs -cat output2/*
/************/





4) Parsing web-logs (python):

/************/
cd python_logs\parse_logs
####IPs por lugar de acceso 
cat access.log | python map_original.py  > output.log
cat access.log | python map_original.py  | python reduce_original.py > output.log

hadoop fs -rm -r input2
hadoop fs -mkdir input2
hadoop fs -copyFromLocal ~/workspace_profesor/data/access.log input2/ 
hadoop fs -ls input2/
hadoop fs -rm -r output2


hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-2.6.0.jar \
-file map_original.py    -mapper map_original.py \
-file reduce_original.py   -reducer reduce_original.py \
-input input2/* -output output2

hadoop fs -cat output2/*
hadoop fs -getmerge output2/ output.txt
/************/



cd python_logs\parse_logs_lugar_acceso
####IPs por lugar de acceso y tipo de conexión 
cat access.log | python map_streaming_final.py  > output.log
cat access.log | python map_streaming_final.py  | python reduce_streaming_final.py > output.log


hadoop fs -copyFromLocal ~/workspace_profesor/data/ips_esquema.csv 
hadoop fs -rm -r output2

hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-2.6.0.jar \
-files ips_esquema.csv \
-file map_streaming_final.py    -mapper map_streaming_final.py \
-file reduce_streaming_final.py   -reducer reduce_streaming_final.py \
-input input2/* -output output2

hadoop fs -cat output2/*

/************/




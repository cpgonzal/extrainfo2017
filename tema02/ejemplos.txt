


Sequential wordcount (python):

/************/
echo "hay muchas, pero que muchas cosas que aprender en esto del big data" | python mapper.py
echo "hay muchas, pero que muchas cosas que aprender en esto del big data" | python mapper.py | sort -k1,1 | python reducer.py

python wordcount.py books.json | sort
/************/




Hadoop wordcount (java):


/************/
cd hadoop_wordcount

javac -classpath $HADOOP_HOME/share/hadoop/common/lib/hadoop-annotations-2.6.7.jar:\
$HADOOP_HOME/share/hadoop/common/hadoop-common-2.6.0.jar:\
$HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.0.jar:\
$HADOOP_HOME/share/hadoop/common/lib/commons-cli-1.2.jar -d bin src/mapred/WordCount.java

cd bin
jar cf mapred.jar mapred/*.class

hadoop fs -mkdir input2
hadoop fs -copyFromLocal ~/workspace_profesor/data/texto_big_data.txt input2/ 
hadoop fs -ls input2/
hadoop jar mapred.jar mapred.WordCount input2 output2
hadoop fs -cat output2/*
hadoop fs -rm -r output2
/**************/

Hadoop wordcount (python):

/************/
hadoop fs -rm -r output2

hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-2.6.0.jar \
-file mapper.py    -mapper mapper.py \
-file reducer.py   -reducer reducer.py \
-input input2/* -output output2

hadoop fs -cat output2/*
/************/





Parsing web-logs (python):


/*IPs por lugar de acceso ***********/
cat access.log | python map_original.py  > output.log
cat access.log | python map_original.py  | python reduce_original.py > output.log

hadoop fs -rm -r input2
hadoop fs -mkdir input2
hadoop fs -copyFromLocal ~/workspace_profesor/data/access.log input2/ 
hadoop fs -ls input2/
hadoop fs -rm -r output2


hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-2.6.0.jar \
-file map_original.py    -mapper map_original.py \
-file reduce_original.py   -reducer reduce_original.py \
-input input2/* -output output2

hadoop fs -cat output2/*
hadoop fs -getmerge output2/ output.txt
/************/



/*IPs por lugar de acceso y tipo de conexión ***********/
cat access.log | python map_streaming_final.py  > output.log
cat access.log | python map_streaming_final.py  | python reduce_streaming_final.py > output.log


hadoop fs -copyFromLocal ~/workspace_profesor/data/ips_esquema.csv 
hadoop fs -rm -r output2

hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-2.6.0.jar \
-files ips_esquema.csv \
-file map_streaming_final.py    -mapper map_streaming_final.py \
-file reduce_streaming_final.py   -reducer reduce_streaming_final.py \
-input input2/* -output output2

hadoop fs -cat output2/*

/************/



